{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as func\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.autograd import variable\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\EssentialSoftware\\python\\lib\\site-packages\\torch\\autograd\\__init__.py:249: UserWarning: torch.autograd.variable(...) is deprecated, use torch.tensor(...) instead\n",
      "  warnings.warn(\"torch.autograd.variable(...) is deprecated, use torch.tensor(...) instead\")\n",
      "D:\\EssentialSoftware\\python\\lib\\site-packages\\torch\\autograd\\__init__.py:250: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "x = torch.unsqueeze(torch.linspace(-1,1,200),dim=1)\n",
    "# y = x.pow(3) + 0.1*torch.randn(x.size())\n",
    "y = x.pow(4) + 0.1*torch.randn(x.size())\n",
    "\n",
    "x,y = (variable(x).cuda(),variable(y).cuda())\n",
    "\n",
    "# plt.scatter(x,y)\n",
    "# # plt.scatter(x.data,y.data)\n",
    "# # plt.scatter(x.data.numpy(),y.data.numpy())\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self,n_input,n_hidden,n_output):\n",
    "        super(Net,self).__init__()\n",
    "        self.hidden1 = nn.Linear(n_input,n_hidden)\n",
    "        self.hidden2 = nn.Linear(n_hidden,n_hidden)\n",
    "        self.hidden3 = nn.Linear(n_hidden,n_hidden)\n",
    "        self.predict = nn.Linear(n_hidden,n_output)\n",
    "    def forward(self,input):\n",
    "        out = self.hidden1(input)\n",
    "        out = torch.relu(out)\n",
    "        out = self.hidden2(out)\n",
    "        out = torch.sigmoid(out)\n",
    "        out = self.predict(out)\n",
    "        \n",
    "        return out\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (hidden1): Linear(in_features=1, out_features=160, bias=True)\n",
      "  (hidden2): Linear(in_features=160, out_features=160, bias=True)\n",
      "  (hidden3): Linear(in_features=160, out_features=160, bias=True)\n",
      "  (predict): Linear(in_features=160, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net = Net(1,160,1)\n",
    "net.to(device)\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adagrad(net.parameters(),lr=0.1)\n",
    "loss_func = torch.nn.MSELoss()\n",
    "plt.ion()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function TransformNode.set_children.<locals>.<lambda> at 0x00000210AA53E790>\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\EssentialSoftware\\python\\lib\\site-packages\\matplotlib\\transforms.py\", line 222, in <lambda>\n",
      "    self, lambda _, pop=child._parents.pop, k=id(self): pop(k))\n",
      "KeyboardInterrupt: \n"
     ]
    }
   ],
   "source": [
    "%matplotlib qt5\n",
    "for t in range(20000):\n",
    "    prediction = net(x)\n",
    "    loss = loss_func(prediction,y)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if t%30 == 0:\n",
    "        plt.cla()\n",
    "        plt.scatter(x.cpu().data.numpy(),y.cpu().data.numpy())\n",
    "        plt.plot(x.cpu().data.numpy(),prediction.cpu().data.numpy(),'r-',lw=5)\n",
    "        plt.text(0.5,0,'Loss=%.4f' % loss.cpu().data, fontdict={'size':20,'color':'red'})\n",
    "        plt.pause(0.001)\n",
    "plt.ioff()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8f0993ed2895456e110aad98b96776962d3006e8c58c574c2eefef3624adea21"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
